<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title>Intro to AI End of Term Assignment</title>
<!-- 2013-12-10 Tue 15:49 -->
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="Andrew Hynes, Samuel Sleight, Helen Cheung, Amar Saggu" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center; }
  .todo   { font-family: monospace; color: red; }
  .done   { color: green; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  pre.src-sh:before    { content: 'sh'; }
  pre.src-bash:before  { content: 'sh'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-R:before     { content: 'R'; }
  pre.src-perl:before  { content: 'Perl'; }
  pre.src-java:before  { content: 'Java'; }
  pre.src-sql:before   { content: 'SQL'; }

  table { border-collapse:collapse; }
  td, th { vertical-align:top;  }
  th.right  { text-align: center;  }
  th.left   { text-align: center;   }
  th.center { text-align: center; }
  td.right  { text-align: right;  }
  td.left   { text-align: left;   }
  td.center { text-align: center; }
  dt { font-weight: bold; }
  .footpara:nth-child(2) { display: inline; }
  .footpara { display: block; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<h1 class="title">Intro to AI End of Term Assignment</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">1. Overview of the Program</a></li>
<li><a href="#sec-2">2. Something Algorithm - By Helen and Amar</a></li>
<li><a href="#sec-3">3. MASH Algorithm - By Sam and Andrew</a>
<ul>
<li><a href="#sec-3-1">3.1. Basis of the Algorithm</a></li>
<li><a href="#sec-3-2">3.2. Design</a>
<ul>
<li><a href="#sec-3-2-1">3.2.1. Probabilistic Learning</a></li>
<li><a href="#sec-3-2-2">3.2.2. Adversarial Search</a></li>
<li><a href="#sec-3-2-3">3.2.3. Alpha-Beta Pruning</a></li>
</ul>
</li>
<li><a href="#sec-3-3">3.3. Analysis of Behaviour</a>
<ul>
<li><a href="#sec-3-3-1">3.3.1. Expectations</a></li>
<li><a href="#sec-3-3-2">3.3.2. Performance</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> Overview of the Program</h2>
<div class="outline-text-2" id="text-1">
<p>
The basic game structure is that the game is represented in an integer array. Positions 0 - 5 represent the top row of houses, position 6 represents the first player's store. Positions 7-12 represent the bottom row of houses, and position 13 represents the second player's store.
</p>

<p>
We had both of our AI extend a class called AIBase, which get passed into the playGame method when they play the game. The AI individually have a method called makeMove, which will implement their algoririthm and will call the "sow" method of the KalahGame class, which will in turn modify the state of the board, ready for the next AI's move.
</p>

<p>
After constructing the infrastructure of the game and whatnot, including the base AI class and all of the plumbing for making sure everything connects properly, we went off into our subgroups and made out individual AI which extend the abstract AIBase class. Needless to say, the methods (such as playGame) take an object of type AIBase, which meant we could do all of the game together before we'd made our AI, utilising abstract classes and methods to denote what each AI should have, such as a win/lose method, which each learning algorithm could take and learn from.
</p>

<p>
We both did have similar ideas in regards to usage of algorithms, and we shared resources found, and ideas about our AI - and there were some cases where methods were useful for both parties, so were put outside the individual AI class, and shared the method for usage in both of our AI, to save time and keep relative concurrence as far as how the AI works is concerned. Despite creating both of AI separately, sharing ideas wasn't something we shied away from.
</p>

<p>
We used GitHub as version control. The repository can be found here - <a href="https://github.com/YeyaSwizaw/kalah">https://github.com/YeyaSwizaw/kalah</a>. We found this was the easiest way to collaborate as a group to create coherent code that meshed well with each other, even despite it not being coded all by one person. This is a lot more efficient and sensible than simply having a dropbox folder, we found, as it's less fiddling around. This made it extremely easy to download the repository from any machine, and push changes from anywhere, without any re-downloading of single files or one zip.
</p>

<p>
The results of our 1000 games were -
</p>

<p>
AI 1 - Helen &amp; Amar's - X/1000 wins
</p>

<p>
AI 2 - Sam &amp; Andrew's - X/1000 wins
</p>
</div>
</div>
<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2"><span class="section-number-2">2</span> Something Algorithm - By Helen and Amar</h2>
<div class="outline-text-2" id="text-2">
<p>
Put stuff here!
</p>
</div>
</div>
<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3"><span class="section-number-2">3</span> MASH Algorithm - By Sam and Andrew</h2>
<div class="outline-text-2" id="text-3">
<p>
This is the algorithm and AI constructed by Sam and Andrew, which can be found in MASH.java.
</p>
</div>

<div id="outline-container-sec-3-1" class="outline-3">
<h3 id="sec-3-1"><span class="section-number-3">3.1</span> Basis of the Algorithm</h3>
<div class="outline-text-3" id="text-3-1">
<p>
We based our algorithm largely on the M&amp;N algorithm - an improement on the mini-max algorithm. We chose this as it has been greatly successful in the past, and an AI written in Lisp utilising this algorithm has won tournaments with other AI based on other algorithms before. In short, the M&amp;N algorithm has been found to perform significantly better than a base mini-max algorithm.
</p>

<p>
We found a PDF on the M&amp;N algorithm here - <a href="http://dl.acm.org/citation.cfm?id=362054">http://dl.acm.org/citation.cfm?id=362054</a> and though it was originally written in Common Lisp, we took the ideas of the M&amp;N algorithm, namely that a min-max algorithm should pick from a few options and take into account relative uncertainty (especially considering the fact that algorithms for this task are designed to learn) - therefore we can't be certain as to whether the opposing AI will modify their moves using what they've learnt (potentially from how our AI plays) from the last game(s).
</p>

<p>
We also took some inspiration from Artificial Intelligence: A Modern Approach, for example, pages 480 - 483, and applied its comments on reasoning under uncertainty to our implementation of the M&amp;N algorithm. We felt it would be prudent, when against any decent learning algorithm, to consider uncertainty when we are unsure, indeed, what move the opposing AI will choose, and whether they will have adapted their efforts from last time. The book proved useful a great deal for referencing in regards to how to construct a sensible AI, and gave us some places to start with algorithms and design. The textbook (and lecture's) comments on probability inspired the probabilistic learning section of our algorithm a great deal, too.
</p>
</div>
</div>
<div id="outline-container-sec-3-2" class="outline-3">
<h3 id="sec-3-2"><span class="section-number-3">3.2</span> Design</h3>
<div class="outline-text-3" id="text-3-2">
<p>
We originally designed a naive base learning algorithm that was based on probability and weighted probability depending on wins/losses. We opted to design this first and then give the algorithm a basis from where to start. In our case, we designed the decision and learning first, via the makeMove method, then fleshed out the search, which was the base our algorithm was going to learn from. Our algorithm was designed with previous games in mind, and we created a HashMap with the "memory" of the game so far, which mapped the GameState with an array of the probibilities based on the results of the last game. Needless to say, the results will be weighted based on how that probability performed, as will be mentioned below.
</p>
</div>

<div id="outline-container-sec-3-2-1" class="outline-4">
<h4 id="sec-3-2-1"><span class="section-number-4">3.2.1</span> Probabilistic Learning</h4>
<div class="outline-text-4" id="text-3-2-1">
<p>
We generated a probability array (represented in a private class ProbArray) based on the probability distribution of the possible moves that can be made. Before the search algorithm and any learning has weighted these distributions, they start at a state such that the sum of the probabilities is 1. Any change to any probability goes through the updateProbability method, which calculates the other probabilities in a way that they remain at 1, even if one of them is increased by an amount.
</p>

<p>
Based on the results of past games, and depending on the result, the probability of certain states will be increased, based on an int defined at the top of the class, PROB DELTA. We can (and did) fiddle with the number a bit to try and perfect the amount of learning our algorithm took from a certain move. It'd be foolish to make it learn too much - as the algorithm would favour things that have worked in the past even if they mightn't work in this situation, likewise with too little, as you don't want the algorithm not learning enough from the results of the previous games. We ran the AI against itself a few times, and based the effectiveness on how often player 1 won proportional to player 2 - as since Kalah is a biased game, as the AI learns, player 1 will win more often.
</p>
</div>
</div>
<div id="outline-container-sec-3-2-2" class="outline-4">
<h4 id="sec-3-2-2"><span class="section-number-4">3.2.2</span> Adversarial Search</h4>
<div class="outline-text-4" id="text-3-2-2">
<p>
As mentioned above, in the Basis of the Algorithm section, the algorithm we mainly looked at was the M&amp;N algorithm, which is an extension of mini-max. We generated a search tree - utilising pruning to keep the algorithm running in an amount of time that's manageable. We used the mini-max algorithm that, of course, modified by the introduction of probability, and the very act of learning from past games. Needless to say, the search was just a place for the algorithm to begin to learn from, and we could have picked an algorithm that wasn't an adversarial search, nor took into account the opponent's moves at all, which would be completely doable for a search algorithm in this case, since it's paired with a learning algorithm. However, this wouldn't be anywhere near as effective as starting with a strong adversarial search algorithm and utilising probability and learning to enhance this base.
</p>

<p>
Our program creates a tree based on the potential outcomes of each move, and assigns a value to each. Since a full search of every possible state is quite obviously not feasible, we search a limited amount, to a capped amount of 5 levels, whereby we use the heuristic of the amount of stones in our pit subtracted by the stones in their pit, where the highest number is the optimal state [that we can see without searching deeper]. Naturally, we can run these states by our previously generated probabilistic learning, and enhance this heuristic by our learning and the element of probability, which can, in turn, create a further level of stochastic behaviour that the opposing AI mightn't expect - and its learning can be slightly quelled by utilising randomness.
</p>
</div>
</div>
<div id="outline-container-sec-3-2-3" class="outline-4">
<h4 id="sec-3-2-3"><span class="section-number-4">3.2.3</span> Alpha-Beta Pruning</h4>
<div class="outline-text-4" id="text-3-2-3">
<p>
We utilised Alpha-Beta Pruning to keep our algorithm even more efficient. The heuristic we mainly utilised was, as mentioned earlier, the amount of seeds we got into our pit minus the amount of seeds they got in theirs. Needless to say, we wanted to prune the branches where we know we do not need to check; these nodes would be both those where the where we know we can get a node that's smaller, and those where we know we can get a node that's bigger, for min-max respectively. This let us search slightly further than we otherwise probably could in a reasonable amount of time, and kept our algorithm succinct and wasting minimal resources. Needless to say, this only works if their AI behaves entirely rationally, and if they implement some degree of randomness, it the pruning could work against us.
</p>
</div>
</div>
</div>
<div id="outline-container-sec-3-3" class="outline-3">
<h3 id="sec-3-3"><span class="section-number-3">3.3</span> Analysis of Behaviour</h3>
<div class="outline-text-3" id="text-3-3">
</div><div id="outline-container-sec-3-3-1" class="outline-4">
<h4 id="sec-3-3-1"><span class="section-number-4">3.3.1</span> Expectations</h4>
<div class="outline-text-4" id="text-3-3-1">
<p>
We expected our algorithm to perform quite well throughout the 1000 games. We expected the learning we utilised to not gain a giant lead from the other AI, rather, to mainly 'keep up with' the opposing team's efforts of learning from our AI. Rather than having a huge boost in improvement as time went on, we expected a slight boost, but that would also be counteracted by the fact the opposing AI was also learning. We expected this from pairing our learning algorithm with a tried and tested adversarial search algorithm.
</p>

<p>
We expected our AI's lead (if one existed) to stay relatively constant as time went on, and any growth or reduction in performance to be slight. Our algorithm didn't start out entirely naively and learn rapidly - it utilised search as well as learning to get a nice foothold immediately.
</p>
</div>
</div>
<div id="outline-container-sec-3-3-2" class="outline-4">
<h4 id="sec-3-3-2"><span class="section-number-4">3.3.2</span> Performance</h4>
<div class="outline-text-4" id="text-3-3-2">
<p>
Our algorithm performed
</p>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Date: 2013-12-13</p>
<p class="author">Author: Andrew Hynes, Samuel Sleight, Helen Cheung, Amar Saggu</p>
<p class="date">Created: 2013-12-10 Tue 15:49</p>
<p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.2.1 (<a href="http://orgmode.org">Org</a> mode 8.2.4)</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
